# ğŸ”§ æ¨èæ–¹æ¡ˆï¼šSQLx Migrationé‡æ„

## ğŸ“Š å½“å‰é—®é¢˜

ä½ çš„é¡¹ç›®ä½¿ç”¨äº†**è¿‡æ—¶çš„æ‰‹å·¥ç»´æŠ¤æ–¹å¼**ï¼š

```rust
// backend/src/database.rs - å½“å‰æ–¹å¼
let schema = include_str!("schema.sql");  // âŒ æ‰‹å·¥ç»´æŠ¤ï¼Œå®¹æ˜“å‡ºé”™
```

## âœ¨ æ¨èæ–¹æ¡ˆï¼šSQLx Migration

### 1ï¸âƒ£ ä¸ºä»€ä¹ˆé€‰æ‹©SQLx Migrationï¼Ÿ

**ä¼˜åŠ¿**ï¼š
- âœ… **æœ€å°æ”¹åŠ¨** - ä½ å·²ç»åœ¨ç”¨SQLxï¼Œåªéœ€å‡çº§ä½¿ç”¨æ–¹å¼
- âœ… **ç‰ˆæœ¬åŒ–ç®¡ç†** - æ¯ä¸ªæ•°æ®åº“å˜æ›´éƒ½æœ‰ç‹¬ç«‹çš„è¿ç§»æ–‡ä»¶
- âœ… **è‡ªåŠ¨åŒæ­¥** - ä¸å†éœ€è¦æ‰‹åŠ¨ç»´æŠ¤ä¸¤ä¸ªschemaæ–‡ä»¶
- âœ… **ç”Ÿäº§ç¯å¢ƒå®‰å…¨** - æ¸è¿›å¼æ•°æ®åº“å‡çº§
- âœ… **å›¢é˜Ÿåä½œ** - æ¯ä¸ªäººçš„æ•°æ®åº“çŠ¶æ€ä¸€è‡´

### 2ï¸âƒ£ é‡æ„æ­¥éª¤

#### ç¬¬1æ­¥ï¼šæ›´æ–°Cargo.toml

```toml
# backend/Cargo.toml
[dependencies]
sqlx = { 
    version = "0.7", 
    features = ["sqlite", "chrono", "uuid", "macros", "runtime-tokio-rustls", "migrate"], 
    default-features = false 
}
```

#### ç¬¬2æ­¥ï¼šåˆ›å»ºmigrationsç›®å½•ç»“æ„

```
backend/
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ 20241014000001_create_users.sql
â”‚   â”œâ”€â”€ 20241014000002_create_shops.sql  
â”‚   â”œâ”€â”€ 20241014000003_create_customers.sql
â”‚   â”œâ”€â”€ 20241014000004_create_sessions.sql
â”‚   â”œâ”€â”€ 20241014000005_create_messages.sql
â”‚   â”œâ”€â”€ 20241014000006_create_shop_staffs.sql
â”‚   â””â”€â”€ 20241014000007_create_unread_counts.sql
â””â”€â”€ src/
    â””â”€â”€ database.rs
```

#### ç¬¬3æ­¥ï¼šå°†ç°æœ‰schemaæ‹†åˆ†æˆè¿ç§»æ–‡ä»¶

```sql
-- migrations/20241014000001_create_users.sql
CREATE TABLE IF NOT EXISTS users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    email VARCHAR(100) UNIQUE,
    display_name VARCHAR(100),
    role VARCHAR(20) NOT NULL DEFAULT 'staff',
    avatar_url TEXT,
    is_active BOOLEAN NOT NULL DEFAULT true,
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_role ON users(role);

CREATE TRIGGER IF NOT EXISTS update_users_timestamp 
AFTER UPDATE ON users
FOR EACH ROW 
BEGIN
    UPDATE users SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
END;
```

```sql
-- migrations/20241014000006_create_shop_staffs.sql  
CREATE TABLE IF NOT EXISTS shop_staffs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    shop_id INTEGER NOT NULL,
    user_id INTEGER NOT NULL,
    role VARCHAR(20) NOT NULL DEFAULT 'staff',
    permissions JSON,
    is_active BOOLEAN NOT NULL DEFAULT true,
    joined_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (shop_id) REFERENCES shops(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    UNIQUE(shop_id, user_id)
);

CREATE INDEX IF NOT EXISTS idx_shop_staffs_shop ON shop_staffs(shop_id);
CREATE INDEX IF NOT EXISTS idx_shop_staffs_user ON shop_staffs(user_id);
```

#### ç¬¬4æ­¥ï¼šæ›´æ–°database.rs

```rust
// backend/src/database.rs
use sqlx::migrate::Migrator;
use sqlx::{sqlite::SqlitePoolOptions, SqlitePool};
use tracing::info;

#[derive(Clone)]
pub struct Database {
    pool: SqlitePool,
}

// åµŒå…¥migrationsç›®å½•
static MIGRATOR: Migrator = sqlx::migrate!("./migrations");

impl Database {
    pub async fn new(database_url: &str) -> Result<Self> {
        let pool = SqlitePoolOptions::new()
            .max_connections(10)
            .connect(database_url)
            .await?;

        Ok(Database { pool })
    }

    pub(crate) fn pool(&self) -> &SqlitePool {
        &self.pool
    }

    pub async fn migrate(&self) -> Result<()> {
        info!("Running database migrations...");
        
        // ä½¿ç”¨SQLx Migration - è‡ªåŠ¨ç®¡ç†ç‰ˆæœ¬
        MIGRATOR.run(&self.pool).await?;
        
        info!("Database migrations completed");
        Ok(())
    }
    
    // ç§»é™¤verify_tablesæ–¹æ³• - SQLx Migrationä¼šè‡ªåŠ¨å¤„ç†
    
    // ... å…¶ä»–æ•°æ®åº“æ–¹æ³•ä¿æŒä¸å˜
}
```

#### ç¬¬5æ­¥ï¼šç”Ÿæˆå®Œæ•´schemaå·¥å…·

```rust
// backend/src/bin/generate_complete_schema.rs
use sqlx::SqlitePool;
use std::fs;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ”§ ç”Ÿæˆå®Œæ•´æ•°æ®åº“schema...");
    
    // åˆ›å»ºä¸´æ—¶å†…å­˜æ•°æ®åº“
    let pool = SqlitePool::connect("sqlite::memory:").await?;
    
    // åº”ç”¨æ‰€æœ‰è¿ç§»
    sqlx::migrate!("./migrations").run(&pool).await?;
    
    // å¯¼å‡ºå®Œæ•´schema
    let tables = sqlx::query_scalar::<_, String>(
        "SELECT sql FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name"
    ).fetch_all(&pool).await?;
    
    let indexes = sqlx::query_scalar::<_, String>(
        "SELECT sql FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%' ORDER BY name"  
    ).fetch_all(&pool).await?;
    
    let triggers = sqlx::query_scalar::<_, String>(
        "SELECT sql FROM sqlite_master WHERE type='trigger' ORDER BY name"
    ).fetch_all(&pool).await?;
    
    // ç”Ÿæˆå®Œæ•´schemaæ–‡ä»¶
    let mut schema = String::new();
    schema.push_str("-- è‡ªåŠ¨ç”Ÿæˆçš„å®Œæ•´æ•°æ®åº“æ¶æ„\n");
    schema.push_str("-- ç”Ÿæˆæ—¶é—´: ");
    schema.push_str(&chrono::Utc::now().to_rfc3339());
    schema.push_str("\n\nPRAGMA foreign_keys = ON;\n\n");
    
    // æ·»åŠ è¡¨
    for table in tables {
        if !table.trim().is_empty() {
            schema.push_str(&table);
            schema.push_str(";\n\n");
        }
    }
    
    // æ·»åŠ ç´¢å¼•
    schema.push_str("-- ç´¢å¼•\n");
    for index in indexes {
        if !index.trim().is_empty() {
            schema.push_str(&index);
            schema.push_str(";\n");
        }
    }
    
    // æ·»åŠ è§¦å‘å™¨
    schema.push_str("\n-- è§¦å‘å™¨\n");
    for trigger in triggers {
        if !trigger.trim().is_empty() {
            schema.push_str(&trigger);
            schema.push_str(";\n");
        }
    }
    
    // ä¿å­˜åˆ°éƒ¨ç½²ç›®å½•
    let output_path = "../ubuntu-deploy-complete/database_schema.sql";
    fs::write(output_path, schema)?;
    
    println!("âœ… Schemaå·²ç”Ÿæˆ: {}", output_path);
    Ok(())
}
```

#### ç¬¬6æ­¥ï¼šæ›´æ–°æ„å»ºè„šæœ¬

```bash
# æ·»åŠ åˆ°package.jsonæˆ–Makefile
generate-schema:
    cd backend && cargo run --bin generate_complete_schema

sync-schema: generate-schema
    echo "âœ… Schemaå·²åŒæ­¥åˆ°éƒ¨ç½²åŒ…"
```

### 3ï¸âƒ£ ä½¿ç”¨æµç¨‹

#### å¼€å‘æ–°åŠŸèƒ½
```bash
# 1. åˆ›å»ºæ–°è¿ç§»
cd backend
sqlx migrate add create_new_table

# 2. ç¼–è¾‘ç”Ÿæˆçš„è¿ç§»æ–‡ä»¶
vim migrations/20241014000008_create_new_table.sql

# 3. åº”ç”¨è¿ç§»
cargo run  # ä¼šè‡ªåŠ¨æ‰§è¡Œmigrate()

# 4. ç”Ÿæˆå®Œæ•´schema
cargo run --bin generate_complete_schema

# 5. æäº¤
git add migrations/ ubuntu-deploy-complete/database_schema.sql
git commit -m "feat: add new table"
```

#### éƒ¨ç½²åˆ°ç”Ÿäº§
```bash
# SQLx Migrationä¼šè‡ªåŠ¨æ£€æŸ¥ç‰ˆæœ¬ï¼Œåªæ‰§è¡Œç¼ºå¤±çš„è¿ç§»
# ä¸éœ€è¦æ‰‹åŠ¨é‡å»ºæ•´ä¸ªæ•°æ®åº“
./elontalk-backend  # å¯åŠ¨æ—¶è‡ªåŠ¨è¿ç§»
```

### 4ï¸âƒ£ ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | å½“å‰æ–¹å¼ï¼ˆæ‰‹å·¥ï¼‰ | SQLx Migration |
|------|------------------|----------------|
| **æ–‡ä»¶åŒæ­¥** | âŒ æ‰‹åŠ¨ï¼Œæ˜“å‡ºé”™ | âœ… è‡ªåŠ¨ç”Ÿæˆ |
| **ç‰ˆæœ¬ç®¡ç†** | âŒ æ— ç‰ˆæœ¬æ§åˆ¶ | âœ… æ¯ä¸ªå˜æ›´æœ‰ç‰ˆæœ¬ |
| **å›¢é˜Ÿåä½œ** | âŒ å®¹æ˜“å†²çª | âœ… Gitå‹å¥½ |
| **ç”Ÿäº§éƒ¨ç½²** | âŒ éœ€è¦é‡å»ºæ•°æ®åº“ | âœ… æ¸è¿›å¼æ›´æ–° |
| **å›æ»šèƒ½åŠ›** | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒdownè¿ç§» |
| **æ•°æ®å®‰å…¨** | âŒ å¯èƒ½ä¸¢å¤±æ•°æ® | âœ… ä¿æŠ¤ç°æœ‰æ•°æ® |

## ğŸ¯ ç«‹å³è¡ŒåŠ¨

è¿™ä¸ªé‡æ„å¯ä»¥**é€æ­¥è¿›è¡Œ**ï¼Œä¸ä¼šå½±å“ç°æœ‰åŠŸèƒ½ï¼š

1. **ç¬¬ä¸€æ­¥**ï¼šå…ˆåˆ›å»ºmigrationsç›®å½•å’Œå·¥å…·
2. **ç¬¬äºŒæ­¥**ï¼šå°†ç°æœ‰schemaæ‹†åˆ†æˆè¿ç§»æ–‡ä»¶  
3. **ç¬¬ä¸‰æ­¥**ï¼šæ›´æ–°database.rsä½¿ç”¨Migration
4. **ç¬¬å››æ­¥**ï¼šåˆ é™¤æ—§çš„schema.sql

**é¢„æœŸæ•ˆæœ**ï¼š
- âœ… å†ä¹Ÿä¸ä¼šå‡ºç°schemaä¸åŒæ­¥é—®é¢˜
- âœ… æ•°æ®åº“å˜æ›´æœ‰å®Œæ•´çš„ç‰ˆæœ¬å†å²
- âœ… å›¢é˜Ÿæˆå‘˜æ•°æ®åº“çŠ¶æ€è‡ªåŠ¨åŒæ­¥
- âœ… ç”Ÿäº§ç¯å¢ƒå®‰å…¨å‡çº§

è¿™æ ·ä½ å°±æœ‰äº†**ç°ä»£åŒ–çš„æ•°æ®åº“ç®¡ç†æ–¹å¼**ï¼Œå®Œå…¨é…å¾—ä¸Šä½ ä¼˜ç§€çš„Ruståç«¯æ¶æ„ï¼